{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression , Lasso\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from PIL import Image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution for task 1 (Lasso) of lab assignment - FDA SS23 by [Bartosz Krajewski]\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.1 Is it possible to solve the lasso optimisation problem analytically? Explain. (3 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes it is possible  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data (change path if necessary)\n",
    "df = pd.read_csv(\"lasso_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['X1','X2','X3','X4','X5','X6']\n",
    "label =['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[columns]\n",
    "y = df[label]\n",
    "y\n",
    "scores = pd.DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.2 Split the data into a train and a test set with appropriate test size. (2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 6336)\n",
      "(500, 6336)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12)\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.3 Fit a linear regression model for Y using all remaining variables on the training data. (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9920848562751585\n",
      "[[ 3.00758594e+00  1.00196108e+00 -3.03883050e-04  1.00196108e+00\n",
      "  -2.00206643e+00 -1.04267519e-03]]\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print(reg.score(X, y))\n",
    "print(reg.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Task 1.4 Make a model prediction on unseen data and assess model performance using a suitable metric. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-18.05989669]\n",
      " [ -0.12886708]\n",
      " [ -5.98064666]\n",
      " ...\n",
      " [ 12.09428139]\n",
      " [  0.05903533]\n",
      " [  8.3511596 ]]\n",
      "Mean squared error: 0.99\n",
      "R^2 score: 0.99\n",
      "[[-4.5746394 ]\n",
      " [ 4.96620411]\n",
      " [-3.72523477]\n",
      " ...\n",
      " [-3.24947989]\n",
      " [-7.02456222]\n",
      " [ 3.71069855]]\n",
      "Mean squared error: 1.03\n",
      "R^2 score: 0.99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_training_pred = reg.predict(X_train)\n",
    "print(y_training_pred)\n",
    "mse_training = mean_squared_error(y_train, y_training_pred)\n",
    "r2_training = r2_score(y_train, y_training_pred)\n",
    "\n",
    "print(\"Mean squared error: {:.2f}\".format(mse_training))\n",
    "print(\"R^2 score: {:.2f}\".format(r2_training))\n",
    "\n",
    "\n",
    "y_test_pred = reg.predict(X_test)\n",
    "print(y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Mean squared error: {:.2f}\".format(mse_test))\n",
    "print(\"R^2 score: {:.2f}\".format(r2_test))\n",
    "scores['linear_model'] = [mse_test, r2_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.5 Perform lasso regression using the same data as in task 1.3 (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/cross-validation-and-hyperparameter-tuning-how-to-optimise-your-machine-learning-model-13f005af9d7d #\n",
    "def cv_comparison(models, X, y, cv):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    cv_accuracies = pd.DataFrame()\n",
    "    maes = []\n",
    "    mses = []\n",
    "    r2s = []\n",
    "    # Loop through the models, run a CV, add the average scores to the DataFrame and the scores of \n",
    "    # all CVs to the list\n",
    "    for model in models:\n",
    "        mae = -np.round(cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv), 4)\n",
    "        maes.append(mae)\n",
    "        mae_avg = round(mae.mean(), 4)\n",
    "        mse = -np.round(cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv), 4)\n",
    "        mses.append(mse)\n",
    "        mse_avg = round(mse.mean(), 4)\n",
    "        r2 = np.round(cross_val_score(model, X, y, scoring='r2', cv=cv), 4)\n",
    "        r2s.append(r2)\n",
    "        r2_avg = round(r2.mean(), 4)\n",
    "        cv_accuracies[str(model)] = [mae_avg, mse_avg, r2_avg]\n",
    "    cv_accuracies.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2']\n",
    "    return cv_accuracies, maes, mses, r2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lasso(alpha=0.001)</th>\n",
       "      <th>Lasso(alpha=0.01)</th>\n",
       "      <th>Lasso(alpha=0.1)</th>\n",
       "      <th>Lasso(alpha=0.2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>0.8126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>1.0021</td>\n",
       "      <td>1.0408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R^2</th>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.9918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Lasso(alpha=0.001)  Lasso(alpha=0.01)  Lasso(alpha=0.1)  \\\n",
       "Mean Absolute Error              0.7930             0.7930            0.7978   \n",
       "Mean Squared Error               0.9892             0.9893            1.0021   \n",
       "R^2                              0.9922             0.9922            0.9921   \n",
       "\n",
       "                     Lasso(alpha=0.2)  \n",
       "Mean Absolute Error            0.8126  \n",
       "Mean Squared Error             1.0408  \n",
       "R^2                            0.9918  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg1 = Lasso(alpha=0.01)\n",
    "lasso_reg2 = Lasso(alpha=0.1)\n",
    "lasso_reg3 = Lasso(alpha=0.2)\n",
    "models = [lasso_reg, lasso_reg1, lasso_reg2, lasso_reg3]\n",
    "\n",
    "\n",
    "comp, maes, mses, r2s = cv_comparison(models, X_train, y_train, 4)\n",
    "comp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen alpha = 0.01, because mean squared error is low enough and R^2 value is close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000905524525255\n",
      "0.9920901661528703\n",
      "1.0206167913565658\n",
      "0.9915086922459957\n"
     ]
    }
   ],
   "source": [
    "lasso_reg = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(X_train, y_train) \n",
    "pred_train_lasso= lasso_reg.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\n",
    "print(r2_score(y_train, pred_train_lasso))\n",
    "\n",
    "pred_test_lasso= lasso_reg.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \n",
    "print(r2_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.6 Compare model performance to the original linear model by using the same metric and test set as in 1.4.\n",
    "# What do you observe? (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.5746394 ]\n",
      " [ 4.96620411]\n",
      " [-3.72523477]\n",
      " ...\n",
      " [-3.24947989]\n",
      " [-7.02456222]\n",
      " [ 3.71069855]]\n",
      "Mean squared error: 1.03\n",
      "R^2 score: 0.99\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_model</th>\n",
       "      <th>lasso_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1.025501</td>\n",
       "      <td>1.025501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R^2</th>\n",
       "      <td>0.991640</td>\n",
       "      <td>0.991640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    linear_model  lasso_model\n",
       "Mean Squared Error      1.025501     1.025501\n",
       "R^2                     0.991640     0.991640"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_lasso_test_pred = lasso_reg.predict(X_test)\n",
    "print(y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Mean squared error: {:.2f}\".format(mse_test))\n",
    "print(\"R^2 score: {:.2f}\".format(r2_test))\n",
    "scores['lasso_model'] = [mse_test, r2_test]\n",
    "scores.index = ['Mean Squared Error', 'R^2']\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.00758594e+00  1.00196108e+00 -3.03883050e-04  1.00196108e+00\n",
      " -2.00206643e+00 -1.04267519e-03]\n",
      "[ 2.90753193e+00  1.97872572e+00 -5.66899876e-05  1.24289829e-06\n",
      " -1.99810548e+00 -0.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_model</th>\n",
       "      <th>lasso_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>3.007586</td>\n",
       "      <td>2.907532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>1.001961</td>\n",
       "      <td>1.978726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>1.001961</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>-2.002066</td>\n",
       "      <td>-1.998105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>-0.001043</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    linear_model  lasso_model\n",
       "X1      3.007586     2.907532\n",
       "X2      1.001961     1.978726\n",
       "X3     -0.000304    -0.000057\n",
       "X4      1.001961     0.000001\n",
       "X5     -2.002066    -1.998105\n",
       "X6     -0.001043    -0.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.DataFrame()\n",
    "coef['linear_model'] = reg.coef_[0]\n",
    "print(reg.coef_[0])\n",
    "print(lasso_reg.coef_)\n",
    "coef['lasso_model'] = lasso_reg.coef_\n",
    "coef.index = ['X1', 'X2' , 'X3', 'X4','X5' , 'X6']\n",
    "coef\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for task 2 (Image Classifier) of lab assignment for FDA SS23 by [Bartosz Krajewski]\n",
    "# imports here\n",
    "import numpy as np   # essential for everything\n",
    "import pandas as pd   # data structure\n",
    "import matplotlib.pyplot as plt   # plots\n",
    "#import seaborn as sns   # fanc plots\n",
    "import sklearn   # standard machine learning\n",
    "import keras   # neural networks (frontend for tensorflow)\n",
    "from keras.models import Sequential  # simplest way to set up neural network model \n",
    "from keras.layers import Dense  # fully connected layer\n",
    "from tensorflow.keras.optimizers import SGD  # stochastic gradient descent\n",
    "import tensorflow as tf  # backend, we only use it to set random seed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 6335)              40144895  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 40)                253440    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,398,335\n",
      "Trainable params: 40,398,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "13/13 [==============================] - 1s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define additional functions here\n",
    "# check that the input has the correct shape\n",
    "\n",
    "# --------------------------\n",
    "# add your data preprocessing, model definition, training and prediction between these lines\n",
    "\n",
    "\n",
    "n_classes = y_train['y'].nunique()\n",
    "model = Sequential()\n",
    "model.add(Dense(6335, activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "            optimizer=SGD(learning_rate=0.01), \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, validation_split=0.2, batch_size=10, verbose=0)\n",
    "#y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# test that the returned prediction has correct shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 6336)\n",
      "(1800, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),  # input layer (1)\n",
    "    keras.layers.Dense(600, activation='relu'),  #  hidden layer (2)\n",
    "\n",
    "    keras.layers.Dense(40, activation='softmax') # output layer (3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       6.0\n",
      "1       6.0\n",
      "2       8.0\n",
      "3       6.0\n",
      "4       6.0\n",
      "       ... \n",
      "6331    5.0\n",
      "6332    4.0\n",
      "6333    0.0\n",
      "6334    5.0\n",
      "6335    3.0\n",
      "Length: 6336, dtype: float64\n",
      "0       255.0\n",
      "1       255.0\n",
      "2       255.0\n",
      "3       255.0\n",
      "4       255.0\n",
      "        ...  \n",
      "6331    255.0\n",
      "6332    255.0\n",
      "6333    255.0\n",
      "6334    255.0\n",
      "6335    255.0\n",
      "Length: 6336, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.min())\n",
    "print(X_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y\n",
       "238    4\n",
       "1035   9\n",
       "1821   3\n",
       "713   32\n",
       "1546  15\n",
       "...   ..\n",
       "739   36\n",
       "988   25\n",
       "102   26\n",
       "1445  31\n",
       "1590  13\n",
       "\n",
       "[1600 rows x 1 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = pd.get_dummies(y_train)\n",
    "y_train = pd.get_dummies(y_train)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y\n",
       "324   10\n",
       "1414   2\n",
       "1365  35\n",
       "1132  26\n",
       "1222   2\n",
       "...   ..\n",
       "689   13\n",
       "460   12\n",
       "124    2\n",
       "967   23\n",
       "621   25\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train /255.0\n",
    "X_test = X_test / 255.0\n",
    "# y_train['y'] = pd.get_dummies(y_train)\n",
    "# y_test[y] = pd.get_dummies(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_60\" is incompatible with the layer: expected shape=(None, 48, 44, 3), found shape=(32, 6336)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[364], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      2\u001b[0m             optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      3\u001b[0m             metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[39m# --------------------------\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train , y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m80\u001b[39;49m ,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32me:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileoy3chrat.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_60\" is incompatible with the layer: expected shape=(None, 48, 44, 3), found shape=(32, 6336)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "            optimizer='adam', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "history = model.fit(X_train , y_train, epochs=80 ,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 40.4939 - accuracy: 0.7875\n",
      "Test accuracy: 0.7875000238418579\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1) \n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"X_train.csv\")\n",
    "y = pd.read_csv(\"y_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nmp = X.to_numpy()\n",
    "X_nmp = X_nmp.reshape(2000,44, 48, 3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nmp, y, test_size = 0.2)\n",
    "\n",
    "X_train = X_train /255\n",
    "X_test = X_test / 255\n",
    "\n",
    "#X_nmp.reshape(2000,48,43,3)\n",
    "X_train\n",
    "drop_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(1600, 44, 48, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[378], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m X_nmp\n\u001b[1;32m----> 2\u001b[0m X_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(X_train)\n",
      "File \u001b[1;32me:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    712\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    713\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    714\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    720\u001b[0m         )\n\u001b[0;32m    721\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    723\u001b[0m             data,\n\u001b[0;32m    724\u001b[0m             index,\n\u001b[0;32m    725\u001b[0m             columns,\n\u001b[0;32m    726\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    727\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    728\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    729\u001b[0m         )\n\u001b[0;32m    731\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32me:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:329\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    324\u001b[0m         values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     \u001b[39m# by definition an array here\u001b[39;00m\n\u001b[0;32m    328\u001b[0m     \u001b[39m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     values \u001b[39m=\u001b[39m _prep_ndarraylike(values, copy\u001b[39m=\u001b[39;49mcopy_on_sanitize)\n\u001b[0;32m    331\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dtype_equal(values\u001b[39m.\u001b[39mdtype, dtype):\n\u001b[0;32m    332\u001b[0m     \u001b[39m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[0;32m    333\u001b[0m     rcf \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m (is_integer_dtype(dtype) \u001b[39mand\u001b[39;00m values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:583\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    581\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m))\n\u001b[0;32m    582\u001b[0m \u001b[39melif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMust pass 2-d input. shape=\u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    585\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(1600, 44, 48, 3)"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 48, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x44>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_nmp[66].shape)\n",
    "array = np.array(X_nmp[19], dtype=np.uint8)\n",
    "img = Image.fromarray(array)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 42, 46, 90)        2520      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 42, 46, 90)       360       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 42, 46, 90)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 39, 43, 90)        129690    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 19, 21, 90)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 19, 21, 90)       360       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 19, 180)       145980    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 9, 180)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 9, 180)        720       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 9, 180)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 5, 180)         291780    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2700)              9722700   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                108040    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,402,150\n",
      "Trainable params: 10,401,430\n",
      "Non-trainable params: 720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(90, (3, 3), activation='relu', input_shape=(44, 48,3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(drop_rate))\n",
    "model.add(layers.Conv2D(90, (4, 4), activation='relu', input_shape=(44, 48,3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(180, (3, 3) , activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(drop_rate))\n",
    "model.add(layers.Conv2D(180, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=2, padding=\"same\"))\n",
    "model.add(layers.Flatten())  # input layer (1)\n",
    "model.add(layers.Dense(2700, activation='relu')) #  hidden layer (2)\n",
    "\n",
    "model.add(layers.Dense(40, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 42, 46, 90)        2520      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 21, 23, 90)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 19, 21, 180)       145980    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 9, 10, 180)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 9, 180)         129780    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12960)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2700)              34994700  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 40)                108040    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,381,020\n",
      "Trainable params: 35,381,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(90, (3, 3), activation='relu', input_shape=(44, 48,3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(180, (3, 3) , activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(180, (2, 2) , activation='relu'))\n",
    "model.add(layers.Flatten())  # input layer (1)\n",
    "model.add(layers.Dense(2700, activation='relu')) #  hidden layer (2)\n",
    "\n",
    "model.add(layers.Dense(40, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "stop = EarlyStopping(monitor=\"accuracy\", min_delta=0, patience=30, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 78s 676ms/step - loss: 0.9648 - accuracy: 0.7156 - val_loss: 0.6936 - val_accuracy: 0.8100\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.3782 - accuracy: 0.8950 - val_loss: 0.6250 - val_accuracy: 0.8300\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 61s 608ms/step - loss: 0.1806 - accuracy: 0.9488 - val_loss: 0.5668 - val_accuracy: 0.8650\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.0853 - accuracy: 0.9769 - val_loss: 0.4491 - val_accuracy: 0.9225\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 61s 607ms/step - loss: 0.0949 - accuracy: 0.9719 - val_loss: 0.4983 - val_accuracy: 0.8875\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 61s 615ms/step - loss: 0.0856 - accuracy: 0.9750 - val_loss: 0.6488 - val_accuracy: 0.8875\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 61s 613ms/step - loss: 0.1160 - accuracy: 0.9712 - val_loss: 0.6008 - val_accuracy: 0.8825\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 61s 613ms/step - loss: 0.1277 - accuracy: 0.9650 - val_loss: 0.6381 - val_accuracy: 0.8850\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 61s 608ms/step - loss: 0.0796 - accuracy: 0.9812 - val_loss: 0.4813 - val_accuracy: 0.8925\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 61s 609ms/step - loss: 0.0116 - accuracy: 0.9975 - val_loss: 0.4703 - val_accuracy: 0.9250\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 61s 606ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5227 - val_accuracy: 0.9250\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 61s 609ms/step - loss: 2.6358e-04 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.9325\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 61s 607ms/step - loss: 1.4347e-04 - accuracy: 1.0000 - val_loss: 0.5199 - val_accuracy: 0.9350\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 61s 607ms/step - loss: 1.0752e-04 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.9350\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 51s 510ms/step - loss: 8.5102e-05 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.9350\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 59s 593ms/step - loss: 6.9610e-05 - accuracy: 1.0000 - val_loss: 0.5453 - val_accuracy: 0.9350\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 64s 642ms/step - loss: 5.8073e-05 - accuracy: 1.0000 - val_loss: 0.5541 - val_accuracy: 0.9350\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 64s 641ms/step - loss: 5.0325e-05 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.9350\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 64s 638ms/step - loss: 4.3335e-05 - accuracy: 1.0000 - val_loss: 0.5658 - val_accuracy: 0.9350\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 3.8415e-05 - accuracy: 1.0000 - val_loss: 0.5704 - val_accuracy: 0.9350\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 58s 584ms/step - loss: 3.3727e-05 - accuracy: 1.0000 - val_loss: 0.5776 - val_accuracy: 0.9350\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 3.0068e-05 - accuracy: 1.0000 - val_loss: 0.5828 - val_accuracy: 0.9350\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 2.6651e-05 - accuracy: 1.0000 - val_loss: 0.5874 - val_accuracy: 0.9325\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 57s 572ms/step - loss: 2.3806e-05 - accuracy: 1.0000 - val_loss: 0.5966 - val_accuracy: 0.9325\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 2.1142e-05 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.9325\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 60s 603ms/step - loss: 1.9294e-05 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.9325\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 1.7089e-05 - accuracy: 1.0000 - val_loss: 0.6092 - val_accuracy: 0.9325\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 1.5691e-05 - accuracy: 1.0000 - val_loss: 0.6148 - val_accuracy: 0.9325\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 67s 671ms/step - loss: 1.4119e-05 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.9300\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 65s 652ms/step - loss: 1.2748e-05 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 0.9300\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 66s 659ms/step - loss: 1.1433e-05 - accuracy: 1.0000 - val_loss: 0.6263 - val_accuracy: 0.9300\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 66s 663ms/step - loss: 1.0684e-05 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.9300\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 9.5278e-06 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.9275\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 59s 588ms/step - loss: 8.6868e-06 - accuracy: 1.0000 - val_loss: 0.6381 - val_accuracy: 0.9275\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 57s 572ms/step - loss: 7.9741e-06 - accuracy: 1.0000 - val_loss: 0.6413 - val_accuracy: 0.9275\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 7.3254e-06 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.9275\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 6.5876e-06 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.9250\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 6.1031e-06 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 0.9250\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 53s 531ms/step - loss: 5.5849e-06 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.9250\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 5.0507e-06 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.9250\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 45s 444ms/step - loss: 4.7718e-06 - accuracy: 1.0000 - val_loss: 0.6644 - val_accuracy: 0.9250\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 40s 405ms/step - loss: 4.3479e-06 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.9250\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "            optimizer='adam', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "history = model.fit(X_train , y_train, epochs=50 , verbose=1, batch_size= 16,  validation_data=(X_test, y_test), callbacks= [stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 2s 94ms/step - loss: 1.6550 - accuracy: 0.5225\n",
      "Test accuracy: 0.5224999785423279\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1) \n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 89ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.4061484e-03, 8.8285195e-04, 1.5382509e-02, 8.7959021e-02,\n",
       "       6.4928159e-02, 2.0036584e-02, 2.0048032e-02, 2.6730448e-02,\n",
       "       2.3805544e-02, 3.4051932e-02, 6.4958477e-01, 1.2770757e-03,\n",
       "       3.0804467e-03, 1.0763048e-02, 8.7246357e-05, 2.3308457e-03,\n",
       "       5.1392242e-03, 2.9639513e-04, 9.1955462e-04, 2.7604692e-04,\n",
       "       3.6669645e-04, 7.3803670e-04, 9.0663481e-05, 6.8279728e-04,\n",
       "       2.3240704e-04, 1.5233996e-03, 1.7345864e-04, 9.1737747e-06,\n",
       "       3.3254531e-04, 1.2517754e-04, 7.0959918e-04, 1.7277985e-03,\n",
       "       1.1457474e-03, 5.4939359e-04, 1.0303578e-03, 1.8291215e-03,\n",
       "       5.1819865e-04, 5.2342773e-04, 1.7543590e-02, 1.1625368e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = model.predict(X_test)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8950162e-04, 1.2678527e-03, 7.1004955e-03, 9.5211370e-03,\n",
       "       1.0687062e-02, 2.9911769e-03, 6.0904160e-04, 1.0919890e-03,\n",
       "       2.7514247e-03, 4.4461252e-05, 5.0885172e-04, 1.9767841e-04,\n",
       "       1.9863671e-04, 4.3841843e-03, 2.0676600e-02, 1.7286022e-04,\n",
       "       1.9298063e-04, 9.3136460e-01, 4.6706706e-04, 2.3779098e-04,\n",
       "       7.1644748e-04, 3.3951880e-04, 1.5452236e-04, 5.6946203e-05,\n",
       "       6.4312859e-05, 1.6023417e-03, 2.0778649e-04, 3.5812927e-06,\n",
       "       1.1521038e-04, 8.4128209e-05, 2.6632749e-04, 5.7323696e-04,\n",
       "       2.4911700e-04, 7.4964350e-06, 2.5707302e-05, 4.2895852e-05,\n",
       "       3.0367020e-05, 2.5932570e-06, 7.9325098e-04, 8.8934630e-06],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.argmax(y1, axis = 1)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.406148e-03</td>\n",
       "      <td>8.828519e-04</td>\n",
       "      <td>1.538251e-02</td>\n",
       "      <td>8.795902e-02</td>\n",
       "      <td>6.492816e-02</td>\n",
       "      <td>2.003658e-02</td>\n",
       "      <td>0.020048</td>\n",
       "      <td>2.673045e-02</td>\n",
       "      <td>2.380554e-02</td>\n",
       "      <td>3.405193e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.095992e-04</td>\n",
       "      <td>1.727798e-03</td>\n",
       "      <td>1.145747e-03</td>\n",
       "      <td>5.493936e-04</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>1.162537e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.592887e-12</td>\n",
       "      <td>7.660428e-12</td>\n",
       "      <td>8.909172e-10</td>\n",
       "      <td>4.040379e-10</td>\n",
       "      <td>1.422414e-09</td>\n",
       "      <td>6.525064e-11</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.325749e-10</td>\n",
       "      <td>2.437959e-11</td>\n",
       "      <td>8.040691e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>5.996849e-10</td>\n",
       "      <td>2.936611e-10</td>\n",
       "      <td>1.315956e-11</td>\n",
       "      <td>2.571671e-07</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.999259</td>\n",
       "      <td>6.176343e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.895016e-04</td>\n",
       "      <td>1.267853e-03</td>\n",
       "      <td>7.100496e-03</td>\n",
       "      <td>9.521137e-03</td>\n",
       "      <td>1.068706e-02</td>\n",
       "      <td>2.991177e-03</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>1.091989e-03</td>\n",
       "      <td>2.751425e-03</td>\n",
       "      <td>4.446125e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.663275e-04</td>\n",
       "      <td>5.732370e-04</td>\n",
       "      <td>2.491170e-04</td>\n",
       "      <td>7.496435e-06</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>8.893463e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.062042e-04</td>\n",
       "      <td>7.285955e-04</td>\n",
       "      <td>1.302116e-03</td>\n",
       "      <td>1.185499e-03</td>\n",
       "      <td>1.390789e-03</td>\n",
       "      <td>6.525833e-04</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>6.483418e-04</td>\n",
       "      <td>5.775781e-04</td>\n",
       "      <td>7.014503e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>8.396495e-02</td>\n",
       "      <td>3.654044e-02</td>\n",
       "      <td>7.583502e-04</td>\n",
       "      <td>6.171109e-04</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>4.909423e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.699448e-04</td>\n",
       "      <td>3.260892e-04</td>\n",
       "      <td>5.675800e-04</td>\n",
       "      <td>1.693414e-03</td>\n",
       "      <td>1.279017e-03</td>\n",
       "      <td>5.687613e-04</td>\n",
       "      <td>0.032675</td>\n",
       "      <td>1.339436e-03</td>\n",
       "      <td>2.639519e-04</td>\n",
       "      <td>7.630056e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791463e-02</td>\n",
       "      <td>4.782563e-03</td>\n",
       "      <td>2.717364e-03</td>\n",
       "      <td>2.018200e-03</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.065579</td>\n",
       "      <td>2.367602e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2.410792e-03</td>\n",
       "      <td>6.569218e-03</td>\n",
       "      <td>5.270671e-03</td>\n",
       "      <td>2.191872e-03</td>\n",
       "      <td>7.947701e-03</td>\n",
       "      <td>5.401983e-03</td>\n",
       "      <td>0.037538</td>\n",
       "      <td>4.255374e-03</td>\n",
       "      <td>9.229945e-04</td>\n",
       "      <td>6.219645e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.843626e-02</td>\n",
       "      <td>2.340933e-02</td>\n",
       "      <td>1.556251e-02</td>\n",
       "      <td>6.101619e-03</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>0.013063</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.140414</td>\n",
       "      <td>5.825500e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>5.349370e-03</td>\n",
       "      <td>5.891832e-03</td>\n",
       "      <td>1.003459e-01</td>\n",
       "      <td>1.943922e-01</td>\n",
       "      <td>2.083582e-01</td>\n",
       "      <td>1.536110e-01</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>7.700671e-02</td>\n",
       "      <td>1.450504e-01</td>\n",
       "      <td>3.222201e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.887840e-04</td>\n",
       "      <td>1.355596e-03</td>\n",
       "      <td>1.126309e-03</td>\n",
       "      <td>3.317757e-04</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>3.109463e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1.559033e-03</td>\n",
       "      <td>5.367341e-03</td>\n",
       "      <td>2.017338e-02</td>\n",
       "      <td>2.112862e-02</td>\n",
       "      <td>1.288771e-02</td>\n",
       "      <td>6.994463e-03</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>3.578847e-03</td>\n",
       "      <td>8.140095e-03</td>\n",
       "      <td>3.303801e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.057428e-03</td>\n",
       "      <td>2.732912e-03</td>\n",
       "      <td>1.457713e-03</td>\n",
       "      <td>6.624394e-05</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>6.419016e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>6.847118e-03</td>\n",
       "      <td>8.122338e-03</td>\n",
       "      <td>1.271389e-01</td>\n",
       "      <td>1.353280e-01</td>\n",
       "      <td>2.175623e-01</td>\n",
       "      <td>1.600840e-01</td>\n",
       "      <td>0.018259</td>\n",
       "      <td>9.923910e-02</td>\n",
       "      <td>9.727872e-02</td>\n",
       "      <td>4.068739e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.015960e-04</td>\n",
       "      <td>1.401612e-03</td>\n",
       "      <td>1.403504e-03</td>\n",
       "      <td>3.680039e-04</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>6.852112e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3.911345e-02</td>\n",
       "      <td>1.726415e-01</td>\n",
       "      <td>1.213746e-01</td>\n",
       "      <td>3.577330e-02</td>\n",
       "      <td>1.250354e-01</td>\n",
       "      <td>4.464173e-02</td>\n",
       "      <td>0.094576</td>\n",
       "      <td>4.343379e-02</td>\n",
       "      <td>2.133620e-02</td>\n",
       "      <td>2.890405e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>6.080797e-03</td>\n",
       "      <td>7.253084e-03</td>\n",
       "      <td>2.239501e-02</td>\n",
       "      <td>1.055675e-03</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.029124</td>\n",
       "      <td>3.158023e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1             2             3             4   \\\n",
       "0    1.406148e-03  8.828519e-04  1.538251e-02  8.795902e-02  6.492816e-02   \n",
       "1    2.592887e-12  7.660428e-12  8.909172e-10  4.040379e-10  1.422414e-09   \n",
       "2    1.895016e-04  1.267853e-03  7.100496e-03  9.521137e-03  1.068706e-02   \n",
       "3    3.062042e-04  7.285955e-04  1.302116e-03  1.185499e-03  1.390789e-03   \n",
       "4    1.699448e-04  3.260892e-04  5.675800e-04  1.693414e-03  1.279017e-03   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "395  2.410792e-03  6.569218e-03  5.270671e-03  2.191872e-03  7.947701e-03   \n",
       "396  5.349370e-03  5.891832e-03  1.003459e-01  1.943922e-01  2.083582e-01   \n",
       "397  1.559033e-03  5.367341e-03  2.017338e-02  2.112862e-02  1.288771e-02   \n",
       "398  6.847118e-03  8.122338e-03  1.271389e-01  1.353280e-01  2.175623e-01   \n",
       "399  3.911345e-02  1.726415e-01  1.213746e-01  3.577330e-02  1.250354e-01   \n",
       "\n",
       "               5         6             7             8             9   ...  \\\n",
       "0    2.003658e-02  0.020048  2.673045e-02  2.380554e-02  3.405193e-02  ...   \n",
       "1    6.525064e-11  0.000001  1.325749e-10  2.437959e-11  8.040691e-11  ...   \n",
       "2    2.991177e-03  0.000609  1.091989e-03  2.751425e-03  4.446125e-05  ...   \n",
       "3    6.525833e-04  0.001435  6.483418e-04  5.775781e-04  7.014503e-04  ...   \n",
       "4    5.687613e-04  0.032675  1.339436e-03  2.639519e-04  7.630056e-04  ...   \n",
       "..            ...       ...           ...           ...           ...  ...   \n",
       "395  5.401983e-03  0.037538  4.255374e-03  9.229945e-04  6.219645e-03  ...   \n",
       "396  1.536110e-01  0.010474  7.700671e-02  1.450504e-01  3.222201e-02  ...   \n",
       "397  6.994463e-03  0.002010  3.578847e-03  8.140095e-03  3.303801e-03  ...   \n",
       "398  1.600840e-01  0.018259  9.923910e-02  9.727872e-02  4.068739e-02  ...   \n",
       "399  4.464173e-02  0.094576  4.343379e-02  2.133620e-02  2.890405e-02  ...   \n",
       "\n",
       "               30            31            32            33        34  \\\n",
       "0    7.095992e-04  1.727798e-03  1.145747e-03  5.493936e-04  0.001030   \n",
       "1    5.996849e-10  2.936611e-10  1.315956e-11  2.571671e-07  0.000721   \n",
       "2    2.663275e-04  5.732370e-04  2.491170e-04  7.496435e-06  0.000026   \n",
       "3    8.396495e-02  3.654044e-02  7.583502e-04  6.171109e-04  0.000398   \n",
       "4    1.791463e-02  4.782563e-03  2.717364e-03  2.018200e-03  0.004785   \n",
       "..            ...           ...           ...           ...       ...   \n",
       "395  4.843626e-02  2.340933e-02  1.556251e-02  6.101619e-03  0.014313   \n",
       "396  2.887840e-04  1.355596e-03  1.126309e-03  3.317757e-04  0.000312   \n",
       "397  2.057428e-03  2.732912e-03  1.457713e-03  6.624394e-05  0.000143   \n",
       "398  3.015960e-04  1.401612e-03  1.403504e-03  3.680039e-04  0.000514   \n",
       "399  6.080797e-03  7.253084e-03  2.239501e-02  1.055675e-03  0.002081   \n",
       "\n",
       "           35        36        37        38            39  \n",
       "0    0.001829  0.000518  0.000523  0.017544  1.162537e-03  \n",
       "1    0.000012  0.000004  0.000002  0.999259  6.176343e-08  \n",
       "2    0.000043  0.000030  0.000003  0.000793  8.893463e-06  \n",
       "3    0.000323  0.000586  0.000289  0.002452  4.909423e-04  \n",
       "4    0.005623  0.004184  0.001447  0.065579  2.367602e-03  \n",
       "..        ...       ...       ...       ...           ...  \n",
       "395  0.013063  0.014869  0.007656  0.140414  5.825500e-03  \n",
       "396  0.001711  0.000293  0.000177  0.002261  3.109463e-04  \n",
       "397  0.000260  0.000216  0.000029  0.001792  6.419016e-05  \n",
       "398  0.001576  0.000436  0.000439  0.004982  6.852112e-04  \n",
       "399  0.004055  0.003941  0.001344  0.029124  3.158023e-03  \n",
       "\n",
       "[400 rows x 40 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(y1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\studia\\foundation_of_data\\projekt1\\fda_lab_ss23\\.venv\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train \n",
    "x_test = X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 40\n",
    "input_shape = (44, 48,3)\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 48  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 60s 6s/step - loss: 5.2069 - accuracy: 0.0597 - top-5-accuracy: 0.2410 - val_loss: 3.1453 - val_accuracy: 0.1688 - val_top-5-accuracy: 0.4563\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 32s 5s/step - loss: 3.4896 - accuracy: 0.1292 - top-5-accuracy: 0.4021 - val_loss: 2.7843 - val_accuracy: 0.2875 - val_top-5-accuracy: 0.5875\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 33s 6s/step - loss: 3.1237 - accuracy: 0.1924 - top-5-accuracy: 0.4875 - val_loss: 2.4914 - val_accuracy: 0.3625 - val_top-5-accuracy: 0.6313\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 30s 5s/step - loss: 2.8219 - accuracy: 0.2361 - top-5-accuracy: 0.5597 - val_loss: 2.2001 - val_accuracy: 0.3750 - val_top-5-accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 36s 6s/step - loss: 2.7010 - accuracy: 0.2806 - top-5-accuracy: 0.5938 - val_loss: 2.1049 - val_accuracy: 0.4125 - val_top-5-accuracy: 0.7437\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 41s 7s/step - loss: 2.4659 - accuracy: 0.3111 - top-5-accuracy: 0.6382 - val_loss: 1.7204 - val_accuracy: 0.4500 - val_top-5-accuracy: 0.8375\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 36s 6s/step - loss: 2.2312 - accuracy: 0.3632 - top-5-accuracy: 0.6958 - val_loss: 1.5608 - val_accuracy: 0.5000 - val_top-5-accuracy: 0.8625\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 2.0124 - accuracy: 0.4104 - top-5-accuracy: 0.7597 - val_loss: 1.3410 - val_accuracy: 0.5688 - val_top-5-accuracy: 0.8875\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 27s 5s/step - loss: 1.8631 - accuracy: 0.4236 - top-5-accuracy: 0.7889 - val_loss: 1.2396 - val_accuracy: 0.5875 - val_top-5-accuracy: 0.9187\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 29s 5s/step - loss: 1.7172 - accuracy: 0.4674 - top-5-accuracy: 0.8250 - val_loss: 1.1132 - val_accuracy: 0.6625 - val_top-5-accuracy: 0.9062\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 1.6453 - accuracy: 0.5028 - top-5-accuracy: 0.8354 - val_loss: 0.9817 - val_accuracy: 0.6875 - val_top-5-accuracy: 0.9500\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 25s 4s/step - loss: 1.4787 - accuracy: 0.5326 - top-5-accuracy: 0.8681 - val_loss: 0.9123 - val_accuracy: 0.7188 - val_top-5-accuracy: 0.9563\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 24s 4s/step - loss: 1.3886 - accuracy: 0.5583 - top-5-accuracy: 0.8903 - val_loss: 0.8594 - val_accuracy: 0.7812 - val_top-5-accuracy: 0.9500\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 22s 4s/step - loss: 1.3231 - accuracy: 0.5750 - top-5-accuracy: 0.9007 - val_loss: 0.7845 - val_accuracy: 0.7437 - val_top-5-accuracy: 0.9563\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 23s 4s/step - loss: 1.2152 - accuracy: 0.6118 - top-5-accuracy: 0.9111 - val_loss: 0.7304 - val_accuracy: 0.7625 - val_top-5-accuracy: 0.9563\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 1.1710 - accuracy: 0.6187 - top-5-accuracy: 0.9208 - val_loss: 0.7011 - val_accuracy: 0.7937 - val_top-5-accuracy: 0.9625\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 25s 4s/step - loss: 1.1557 - accuracy: 0.6306 - top-5-accuracy: 0.9299 - val_loss: 0.7291 - val_accuracy: 0.7688 - val_top-5-accuracy: 0.9750\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.9841 - accuracy: 0.6799 - top-5-accuracy: 0.9424 - val_loss: 0.6544 - val_accuracy: 0.8125 - val_top-5-accuracy: 0.9688\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.9879 - accuracy: 0.6722 - top-5-accuracy: 0.9465 - val_loss: 0.6465 - val_accuracy: 0.8000 - val_top-5-accuracy: 0.9563\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.9311 - accuracy: 0.7097 - top-5-accuracy: 0.9542 - val_loss: 0.5828 - val_accuracy: 0.8062 - val_top-5-accuracy: 0.9625\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 33s 6s/step - loss: 0.8715 - accuracy: 0.7201 - top-5-accuracy: 0.9542 - val_loss: 0.5805 - val_accuracy: 0.8500 - val_top-5-accuracy: 0.9750\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.7956 - accuracy: 0.7278 - top-5-accuracy: 0.9597 - val_loss: 0.5690 - val_accuracy: 0.8188 - val_top-5-accuracy: 0.9812\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.8050 - accuracy: 0.7257 - top-5-accuracy: 0.9667 - val_loss: 0.5094 - val_accuracy: 0.8125 - val_top-5-accuracy: 0.9625\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.7510 - accuracy: 0.7444 - top-5-accuracy: 0.9688 - val_loss: 0.5699 - val_accuracy: 0.8188 - val_top-5-accuracy: 0.9688\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7368 - accuracy: 0.7542 - top-5-accuracy: 0.9715 - val_loss: 0.5363 - val_accuracy: 0.8313 - val_top-5-accuracy: 0.9688\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7267 - accuracy: 0.7542 - top-5-accuracy: 0.9771 - val_loss: 0.4893 - val_accuracy: 0.8188 - val_top-5-accuracy: 0.9875\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6739 - accuracy: 0.7590 - top-5-accuracy: 0.9771 - val_loss: 0.5336 - val_accuracy: 0.8250 - val_top-5-accuracy: 0.9812\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 34s 6s/step - loss: 0.7325 - accuracy: 0.7500 - top-5-accuracy: 0.9778 - val_loss: 0.4935 - val_accuracy: 0.8562 - val_top-5-accuracy: 0.9875\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6455 - accuracy: 0.7812 - top-5-accuracy: 0.9792 - val_loss: 0.5443 - val_accuracy: 0.8313 - val_top-5-accuracy: 0.9750\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.6062 - accuracy: 0.7882 - top-5-accuracy: 0.9861 - val_loss: 0.5112 - val_accuracy: 0.8125 - val_top-5-accuracy: 0.9812\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.5580 - accuracy: 0.8007 - top-5-accuracy: 0.9917 - val_loss: 0.4494 - val_accuracy: 0.8500 - val_top-5-accuracy: 0.9750\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.5735 - accuracy: 0.8076 - top-5-accuracy: 0.9840 - val_loss: 0.5025 - val_accuracy: 0.8500 - val_top-5-accuracy: 0.9875\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.5759 - accuracy: 0.7917 - top-5-accuracy: 0.9799 - val_loss: 0.4919 - val_accuracy: 0.8562 - val_top-5-accuracy: 0.9937\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.5488 - accuracy: 0.8215 - top-5-accuracy: 0.9861 - val_loss: 0.5257 - val_accuracy: 0.8375 - val_top-5-accuracy: 0.9812\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.5298 - accuracy: 0.8062 - top-5-accuracy: 0.9868 - val_loss: 0.4628 - val_accuracy: 0.8500 - val_top-5-accuracy: 0.9750\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5045 - accuracy: 0.8299 - top-5-accuracy: 0.9889 - val_loss: 0.3862 - val_accuracy: 0.8750 - val_top-5-accuracy: 0.9812\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.4908 - accuracy: 0.8271 - top-5-accuracy: 0.9882 - val_loss: 0.4099 - val_accuracy: 0.8500 - val_top-5-accuracy: 0.9875\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.4875 - accuracy: 0.8382 - top-5-accuracy: 0.9868 - val_loss: 0.4013 - val_accuracy: 0.8687 - val_top-5-accuracy: 0.9812\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.4510 - accuracy: 0.8417 - top-5-accuracy: 0.9951 - val_loss: 0.3953 - val_accuracy: 0.8687 - val_top-5-accuracy: 0.9875\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.4128 - accuracy: 0.8562 - top-5-accuracy: 0.9931 - val_loss: 0.3632 - val_accuracy: 0.8938 - val_top-5-accuracy: 0.9937\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.4224 - accuracy: 0.8611 - top-5-accuracy: 0.9924 - val_loss: 0.4166 - val_accuracy: 0.8750 - val_top-5-accuracy: 0.9812\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.4279 - accuracy: 0.8604 - top-5-accuracy: 0.9910 - val_loss: 0.4399 - val_accuracy: 0.8625 - val_top-5-accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.3936 - accuracy: 0.8583 - top-5-accuracy: 0.9965 - val_loss: 0.4723 - val_accuracy: 0.8750 - val_top-5-accuracy: 0.9812\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.4215 - accuracy: 0.8521 - top-5-accuracy: 0.9924 - val_loss: 0.4549 - val_accuracy: 0.8750 - val_top-5-accuracy: 0.9750\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.4184 - accuracy: 0.8549 - top-5-accuracy: 0.9937 - val_loss: 0.4388 - val_accuracy: 0.8750 - val_top-5-accuracy: 0.9875\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.4231 - accuracy: 0.8604 - top-5-accuracy: 0.9931 - val_loss: 0.4331 - val_accuracy: 0.8750 - val_top-5-accuracy: 0.9875\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.4018 - accuracy: 0.8618 - top-5-accuracy: 0.9931 - val_loss: 0.3751 - val_accuracy: 0.8813 - val_top-5-accuracy: 0.9875\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.3940 - accuracy: 0.8653 - top-5-accuracy: 0.9910 - val_loss: 0.3861 - val_accuracy: 0.8813 - val_top-5-accuracy: 0.9812\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.3771 - accuracy: 0.8660 - top-5-accuracy: 0.9937 - val_loss: 0.3683 - val_accuracy: 0.8875 - val_top-5-accuracy: 0.9937\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3408 - accuracy: 0.8778 - top-5-accuracy: 0.9951 - val_loss: 0.3245 - val_accuracy: 0.9000 - val_top-5-accuracy: 0.9875\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.3804 - accuracy: 0.8771 - top-5-accuracy: 0.9917 - val_loss: 0.3701 - val_accuracy: 0.8813 - val_top-5-accuracy: 0.9875\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.3191 - accuracy: 0.8875 - top-5-accuracy: 0.9986 - val_loss: 0.4576 - val_accuracy: 0.8562 - val_top-5-accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3325 - accuracy: 0.8861 - top-5-accuracy: 0.9951 - val_loss: 0.4418 - val_accuracy: 0.8625 - val_top-5-accuracy: 0.9937\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 21s 4s/step - loss: 0.3315 - accuracy: 0.8854 - top-5-accuracy: 0.9972 - val_loss: 0.3889 - val_accuracy: 0.8813 - val_top-5-accuracy: 0.9875\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.3043 - accuracy: 0.8931 - top-5-accuracy: 0.9972 - val_loss: 0.3693 - val_accuracy: 0.8938 - val_top-5-accuracy: 0.9937\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.3061 - accuracy: 0.8924 - top-5-accuracy: 0.9944 - val_loss: 0.3897 - val_accuracy: 0.8813 - val_top-5-accuracy: 0.9937\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3065 - accuracy: 0.8965 - top-5-accuracy: 0.9979 - val_loss: 0.3230 - val_accuracy: 0.8938 - val_top-5-accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.2850 - accuracy: 0.9035 - top-5-accuracy: 0.9951 - val_loss: 0.3807 - val_accuracy: 0.8938 - val_top-5-accuracy: 0.9812\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.2904 - accuracy: 0.9021 - top-5-accuracy: 0.9972 - val_loss: 0.3788 - val_accuracy: 0.8813 - val_top-5-accuracy: 0.9937\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.3010 - accuracy: 0.8958 - top-5-accuracy: 0.9965 - val_loss: 0.3553 - val_accuracy: 0.8875 - val_top-5-accuracy: 0.9937\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 27s 5s/step - loss: 0.2509 - accuracy: 0.9118 - top-5-accuracy: 0.9986 - val_loss: 0.3660 - val_accuracy: 0.9062 - val_top-5-accuracy: 0.9875\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.2935 - accuracy: 0.9069 - top-5-accuracy: 0.9944 - val_loss: 0.4042 - val_accuracy: 0.8938 - val_top-5-accuracy: 0.9875\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 21s 4s/step - loss: 0.2610 - accuracy: 0.9097 - top-5-accuracy: 0.9979 - val_loss: 0.3832 - val_accuracy: 0.8813 - val_top-5-accuracy: 0.9937\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.2515 - accuracy: 0.9215 - top-5-accuracy: 0.9979 - val_loss: 0.4072 - val_accuracy: 0.8687 - val_top-5-accuracy: 0.9812\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.2994 - accuracy: 0.9090 - top-5-accuracy: 0.9972 - val_loss: 0.3418 - val_accuracy: 0.8938 - val_top-5-accuracy: 0.9875\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 22s 3s/step - loss: 0.2463 - accuracy: 0.9181 - top-5-accuracy: 0.9972 - val_loss: 0.3039 - val_accuracy: 0.9062 - val_top-5-accuracy: 0.9937\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.2736 - accuracy: 0.9021 - top-5-accuracy: 0.9979 - val_loss: 0.3306 - val_accuracy: 0.8875 - val_top-5-accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.2772 - accuracy: 0.9097 - top-5-accuracy: 0.9979 - val_loss: 0.3002 - val_accuracy: 0.9062 - val_top-5-accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.2659 - accuracy: 0.9125 - top-5-accuracy: 0.9972 - val_loss: 0.3161 - val_accuracy: 0.9250 - val_top-5-accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.2481 - accuracy: 0.9153 - top-5-accuracy: 0.9979 - val_loss: 0.3132 - val_accuracy: 0.9000 - val_top-5-accuracy: 0.9875\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 27s 5s/step - loss: 0.2256 - accuracy: 0.9208 - top-5-accuracy: 0.9986 - val_loss: 0.2810 - val_accuracy: 0.9312 - val_top-5-accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 27s 5s/step - loss: 0.2328 - accuracy: 0.9222 - top-5-accuracy: 0.9993 - val_loss: 0.3599 - val_accuracy: 0.9000 - val_top-5-accuracy: 0.9875\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.2255 - accuracy: 0.9215 - top-5-accuracy: 0.9986 - val_loss: 0.3156 - val_accuracy: 0.9125 - val_top-5-accuracy: 0.9937\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.2484 - accuracy: 0.9229 - top-5-accuracy: 0.9958 - val_loss: 0.3553 - val_accuracy: 0.8938 - val_top-5-accuracy: 0.9937\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.2260 - accuracy: 0.9208 - top-5-accuracy: 0.9958 - val_loss: 0.3287 - val_accuracy: 0.8875 - val_top-5-accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.2156 - accuracy: 0.9292 - top-5-accuracy: 0.9986 - val_loss: 0.2974 - val_accuracy: 0.9187 - val_top-5-accuracy: 0.9875\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.2288 - accuracy: 0.9285 - top-5-accuracy: 0.9979 - val_loss: 0.2937 - val_accuracy: 0.9062 - val_top-5-accuracy: 0.9875\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.2282 - accuracy: 0.9236 - top-5-accuracy: 0.9986 - val_loss: 0.2596 - val_accuracy: 0.9187 - val_top-5-accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.2339 - accuracy: 0.9160 - top-5-accuracy: 0.9986 - val_loss: 0.3290 - val_accuracy: 0.9125 - val_top-5-accuracy: 0.9937\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.2009 - accuracy: 0.9319 - top-5-accuracy: 0.9972 - val_loss: 0.3309 - val_accuracy: 0.8938 - val_top-5-accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.2021 - accuracy: 0.9340 - top-5-accuracy: 0.9965 - val_loss: 0.3281 - val_accuracy: 0.9125 - val_top-5-accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 27s 5s/step - loss: 0.2055 - accuracy: 0.9299 - top-5-accuracy: 0.9986 - val_loss: 0.3090 - val_accuracy: 0.9000 - val_top-5-accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.2000 - accuracy: 0.9340 - top-5-accuracy: 0.9993 - val_loss: 0.2660 - val_accuracy: 0.9062 - val_top-5-accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.1893 - accuracy: 0.9347 - top-5-accuracy: 0.9986 - val_loss: 0.3139 - val_accuracy: 0.9000 - val_top-5-accuracy: 0.9937\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.1945 - accuracy: 0.9403 - top-5-accuracy: 0.9993 - val_loss: 0.3116 - val_accuracy: 0.9000 - val_top-5-accuracy: 0.9937\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.1899 - accuracy: 0.9410 - top-5-accuracy: 0.9986 - val_loss: 0.2920 - val_accuracy: 0.9250 - val_top-5-accuracy: 0.9937\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.2083 - accuracy: 0.9222 - top-5-accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.9125 - val_top-5-accuracy: 0.9937\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.2055 - accuracy: 0.9361 - top-5-accuracy: 0.9986 - val_loss: 0.3576 - val_accuracy: 0.9125 - val_top-5-accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.2017 - accuracy: 0.9306 - top-5-accuracy: 0.9993 - val_loss: 0.3004 - val_accuracy: 0.9250 - val_top-5-accuracy: 0.9937\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 27s 5s/step - loss: 0.2120 - accuracy: 0.9257 - top-5-accuracy: 0.9993 - val_loss: 0.3173 - val_accuracy: 0.9062 - val_top-5-accuracy: 0.9937\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.1862 - accuracy: 0.9354 - top-5-accuracy: 0.9979 - val_loss: 0.3520 - val_accuracy: 0.8875 - val_top-5-accuracy: 0.9937\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.1585 - accuracy: 0.9514 - top-5-accuracy: 0.9986 - val_loss: 0.3423 - val_accuracy: 0.9062 - val_top-5-accuracy: 0.9937\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.1722 - accuracy: 0.9438 - top-5-accuracy: 0.9993 - val_loss: 0.3140 - val_accuracy: 0.9000 - val_top-5-accuracy: 0.9937\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.1477 - accuracy: 0.9549 - top-5-accuracy: 0.9986 - val_loss: 0.2894 - val_accuracy: 0.9250 - val_top-5-accuracy: 0.9937\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.1584 - accuracy: 0.9424 - top-5-accuracy: 0.9993 - val_loss: 0.2823 - val_accuracy: 0.9250 - val_top-5-accuracy: 0.9875\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.1305 - accuracy: 0.9604 - top-5-accuracy: 0.9993 - val_loss: 0.2853 - val_accuracy: 0.9250 - val_top-5-accuracy: 0.9937\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.1791 - accuracy: 0.9389 - top-5-accuracy: 0.9979 - val_loss: 0.2802 - val_accuracy: 0.9187 - val_top-5-accuracy: 0.9937\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.1767 - accuracy: 0.9403 - top-5-accuracy: 0.9993 - val_loss: 0.2821 - val_accuracy: 0.9125 - val_top-5-accuracy: 0.9937\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.1522 - accuracy: 0.9549 - top-5-accuracy: 0.9993 - val_loss: 0.2936 - val_accuracy: 0.8938 - val_top-5-accuracy: 0.9937\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.1867 - accuracy: 0.9417 - top-5-accuracy: 0.9979 - val_loss: 0.2819 - val_accuracy: 0.9187 - val_top-5-accuracy: 0.9937\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.4616 - accuracy: 0.8850 - top-5-accuracy: 0.9825\n",
      "Test accuracy: 88.5%\n",
      "Test top 5 accuracy: 98.25%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"./tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
